confusion matrix: 
[[0 0 0 0 5 0 0]
 [0 0 0 0 5 0 0]
 [0 0 0 0 5 0 0]
 [0 0 0 0 5 0 0]
 [0 0 0 0 0 0 0]
 [0 0 0 0 4 1 0]
 [0 0 0 0 4 0 0]]
classification report: 
              precision    recall  f1-score   support

   Amenities       0.00      0.00      0.00         5
  Cleaniness       0.00      0.00      0.00         5
     General       0.00      0.00      0.00         5
    Location       0.00      0.00      0.00         5
        None       0.00      0.00      0.00         0
    Services       1.00      0.20      0.33         5
       Value       0.00      0.00      0.00         4

    accuracy                           0.03        29
   macro avg       0.14      0.03      0.05        29
weighted avg       0.17      0.03      0.06        29

accuracy score: 3.4482758620689653%
Explanation Generated by Chatgpt.
f1 score:
It is the harmonic mean of precision and recall. It balances the trade-off between precision and recall.
It is particularly useful when you want to find an optimal balance between false positives and false negatives.

precision:
measures the accuracy of positive predictions made by a model.
It is the ratio of true positive predictions to all positive predictions (true positives + false positives).
High precision means that the model makes few false positive errors.

recall:
measures the models ability to find all the positive instances in the dataset. 
It is the ratio of true positive predictions to all actual positive instances (true positives + false negatives). 
High recall means the model does not miss many positive instances.

support:
It represents the number of occurrences of each class in the dataset. 
It helps provide context about the distribution of classes.

accuracy score:
It is the ratio of correct predictions to total predictions made.