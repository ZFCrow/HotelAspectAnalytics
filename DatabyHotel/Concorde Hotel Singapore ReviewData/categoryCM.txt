confusion matrix: 
[[0 0 0 0 4 1 0]
 [0 0 0 2 3 0 0]
 [0 0 0 0 4 0 1]
 [0 0 0 0 5 0 0]
 [0 0 0 0 0 0 0]
 [0 0 1 1 3 0 0]
 [0 0 0 0 4 1 0]]
classification report: 
              precision    recall  f1-score   support

   Amenities       0.00      0.00      0.00       5.0
  Cleaniness       0.00      0.00      0.00       5.0
     General       0.00      0.00      0.00       5.0
    Location       0.00      0.00      0.00       5.0
        None       0.00      0.00      0.00       0.0
    Services       0.00      0.00      0.00       5.0
       Value       0.00      0.00      0.00       5.0

    accuracy                           0.00      30.0
   macro avg       0.00      0.00      0.00      30.0
weighted avg       0.00      0.00      0.00      30.0

accuracy score: 0.0%
Explanation Generated by Chatgpt.
f1 score:
It is the harmonic mean of precision and recall. It balances the trade-off between precision and recall.
It is particularly useful when you want to find an optimal balance between false positives and false negatives.

precision:
measures the accuracy of positive predictions made by a model.
It is the ratio of true positive predictions to all positive predictions (true positives + false positives).
High precision means that the model makes few false positive errors.

recall:
measures the models ability to find all the positive instances in the dataset. 
It is the ratio of true positive predictions to all actual positive instances (true positives + false negatives). 
High recall means the model does not miss many positive instances.

support:
It represents the number of occurrences of each class in the dataset. 
It helps provide context about the distribution of classes.

accuracy score:
It is the ratio of correct predictions to total predictions made.